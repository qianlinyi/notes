# Neural Networks and Deep Learning

## Introduction to Deep Learning

### What is a Neural Network

Housing Price Prediction

![在这里插入图片描述](https://img-blog.csdnimg.cn/3a270dbb64d84da8bcf14e42386ba016.png)

ReLU 激活函数 max(0,x)

修正线性单元 Rectified Linear Unit 取不小于 0 的值

![在这里插入图片描述](https://img-blog.csdnimg.cn/0ac5757545024bb3b79a651c234c3e2c.png)

神经元可以看作是乐高积木，可以通过搭积木的方式获得一个更大的神经网络

![在这里插入图片描述](https://img-blog.csdnimg.cn/d0526b6c7af5431894be77d19e513a76.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/645c52a1b1364fbf9aa221570dfb923b.png)

神经网络的一部分神奇之处在于，当你实现它之后，你要做的只是输入 x，就能得到输出 y。因为它可以自己计算你训练集中样本的数目以及所有的中间过程。所以，你实际上要做的就是：这里有四个输入的神经网络，这输入的特征可能是房屋的大小、卧室的数量、邮政编码和区域的富裕程度。给出这些输入的特征之后，神经网络的工作就是预测对应的价格。同时也注意到这些被叫做隐藏单元圆圈，在一个神经网络中，它们每个都从输入的四个特征获得自身输入，比如说，第一个结点代表家庭人口，而家庭人口仅仅取决于 $x_1$  和 $x_2$  特征，换句话说，在神经网络中，你决定在这个结点中想要得到什么，然后用所有的四个输入来计算想要得到的。因此，我们说输入层和中间层被紧密的连接起来了。

### Supervised Learning with Neural Networks

关于神经网络也有很多的种类，考虑到它们的使用效果，有些使用起来恰到好处，但事实表明，到目前几乎所有由神经网络创造的经济价值，本质上都离不开一种叫做监督学习的机器学习类别，让我们举例看看。

在监督学习中你有一些输入 x ，你想学习到一个函数来映射到一些输出 y，比如我们之前提到的房价预测的例子，你只要输入有关房屋的一些特征，试着去输出或者估计价格 y。我们举一些其它的例子，来说明神经网络已经被高效应用到其它地方。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200403222046889.png)

对于房地产和在线广告老师，经常使用相对标准一些的神经网络

对于图像数据，经常使用卷积神经网络 CNN

对于序列数据，例如音频，经常使用循环神经网络 RNN

![在这里插入图片描述](https://img-blog.csdnimg.cn/28315a3f673f4d9e902898c3e8c9573a.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/68f3f2b0ce3440f997fface12e87c095.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200403222312201.png)

### Why is Deep Learning taking off ？

在水平轴上画一个形状，在此绘制出所有任务的数据量，而在垂直轴上，画出机器学习算法的性能。比如说准确率体现在垃圾邮件过滤或者广告点击预测，或者是神经网络在自动驾驶汽车时判断位置的准确性，根据图像可以发现，如果你把一个传统机器学习算法的性能画出来，作为数据量的一个函数，你可能得到一个弯曲的线，就像图中这样，它的性能一开始在增加更多数据时会上升，但是一段变化后它的性能就会像一个平原一样。假设你的水平轴拉的很长很长，它们不知道如何处理规模巨大的数据，而过去十年的社会里，我们遇到的很多问题只有相对较少的数据量。

![在这里插入图片描述](https://img-blog.csdnimg.cn/202004032224337.png)

多亏数字化社会的来临，现在的数据量都非常巨大，我们花了很多时间活动在这些数字的领域，比如在电脑网站上、在手机软件上以及其它数字化的服务，它们都能创建数据，同时便宜的相机被配置到移动电话，还有加速仪及各类各样的传感器，同时在物联网领域我们也收集到了越来越多的数据。仅仅在过去的 20 年里对于很多应用，我们便收集到了大量的数据，远超过机器学习算法能够高效发挥它们优势的规模。

神经网络展现出的是，如果你训练一个小型的神经网络，那么这个性能可能会像下图黄色曲线表示那样；如果你训练一个稍微大一点的神经网络，比如说一个中等规模的神经网络（下图蓝色曲线），它在某些数据上面的性能也会更好一些；如果你训练一个非常大的神经网络，它就会变成下图绿色曲线那样，并且保持变得越来越好。因此可以注意到两点：如果你想要获得较高的性能体现，那么你有两个条件要完成，第一个是你需要训练一个规模足够大的神经网络，以发挥数据规模量巨大的优点，另外你需要能画到 x xx 轴的这个位置，所以你需要很多的数据。因此我们经常说规模一直在推动深度学习的进步，这里的规模指的也同时是神经网络的规模，我们需要一个带有许多隐藏单元的神经网络，也有许多的参数及关联性，就如同需要大规模的数据一样。事实上如今最可靠的方法来在神经网络上获得更好的性能，往往就是要么训练一个更大的神经网络，要么投入更多的数据，这只能在一定程度上起作用，因为最终你耗尽了数据，或者最终你的网络是如此大规模导致将要用太久的时间去训练，但是仅仅提升规模的的确确地让我们在深度学习的世界中摸索了很多时间。为了使这个图更加从技术上讲更精确一点，我在 x 轴下面已经写明的数据量，这儿加上一个标签（label）量，通过添加这个标签量，也就是指在训练样本时，我们同时输入 x 和标签 y，接下来引入一点符号，使用小写的字母 m 表示训练集的规模，或者说训练样本的数量，这个小写字母 m 就横轴结合其他一些细节到这个图像中。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200403222612316.png)

所以可以这么说，在深度学习萌芽的初期，数据的规模以及计算量，局限在我们对于训练一个特别大的神经网络的能力，无论是在CPU还是GPU上面，那都使得我们取得了巨大的进步。但是渐渐地，尤其是在最近这几年，我们也见证了算法方面的极大创新。许多算法方面的创新，一直是在尝试着使得神经网络运行的更快。

作为一个具体的例子，神经网络方面的一个巨大突破是从 sigmoid 函数转换到一个 ReLU 函数，这个函数我们在之前的课程里提到过。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200403222654711.png)

如果你无法理解刚才我说的某个细节，也不需要担心，可以知道的一个使用sigmoid函数和机器学习问题是，在这个区域，也就是这个sigmoid函数的梯度会接近零，所以学习的速度会变得非常缓慢，因为当你实现梯度下降以及梯度接近零的时候，参数会更新的很慢，所以学习的速率也会变的很慢，而通过改变这个被叫做激活函数的东西，神经网络换用这一个函数，叫做ReLU的函数（修正线性单元），ReLU它的梯度对于所有输入的负值都是零，因此梯度更加不会趋向逐渐减少到零。而这里的梯度，这条线的斜率在这左边是零，仅仅通过将Sigmod函数转换成ReLU函数，便能够使得一个叫做梯度下降（gradient descent）的算法运行的更快，这就是一个或许相对比较简单的算法创新的例子。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200403222744990.png)

## Basics of Neural Network Programming

### Binary Classification

logistic regression 逻辑回归

逻辑回归是一个用于二分类(binary classification)的算法。首先我们从一个问题开始说起，这里有一个二分类问题的例子，假如你有一张图片作为输入，比如这只猫，如果识别这张图片为猫，则输出标签1作为结果；如果识别出不是猫，那么输出标签0作为结果。现在我们可以用字母 来 表示输出的结果标签，如下图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404155904324.png)

我们来看看一张图片在计算机中是如何表示的，为了保存一张图片，需要保存三个矩阵，它们分别对应图片中的红、绿、蓝三种颜色通道，如果你的图片大小为 64x64 像素，那么你就有三个规模为 64x64 的矩阵，分别对应图片中红、绿、蓝三种像素的强度值。为了便于表示，这里我画了三个很小的矩阵，注意它们的规模为 5x4 而不是64x64，如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404155924145.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404160212670.png)

符号定义

$x$: 表示一个 $n_x$ 维数据，为输入数据，维度为 $(n_x,1)$；

$y$: 表示输出结果，取值为 $(0,1)$；

$(x^{(i)},y^{(i)})$: 表示第 $i$ 组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据；

$X=[x^{(1)},x^{(2)},...,x^{(m)}]$: 表示所有的训练数据集的输入值，放入一个 $n_x\times m$ 的矩阵中，其中 $m$ 代表样本数量；

$Y=[y^{(1)},y^{(2)},...,y^{(m)}]$: 表示所有训练数据集的输出值，维度为 $1\times m$。

用一对 $(x,y)$ 来表示一个单独的样本，$x$ 表示 $n_x$ 维的特征向量，$y$ 表示标签（输出结果）只能为 0 或 1。而训练集将由 $m$ 个训练样本组成，其中 $(x^{(1)},y^{(1)})$ 表示第一个样本的输入和输出，直到最后一个样本 $(x^{(m)},y^{(m)})$ ，然后所有的这些一起表示整个训练集。有时候为了强调这是训练样本的个数，会写作 $M_{train}$，当涉及到测试集的时候，我们会使用 $M_{test}$ 来表示测试集的样本数，所以这是测试集的样本数：

![image-20220914164213984](/Users/zaizai/Library/Application Support/typora-user-images/image-20220914164213984.png)

最后为了能把训练集表示得更紧凑一点，我们会定义一个矩阵 $X$，它由输入向量 $x^{(1)},x^{(2)}$ 等组成，如下图放在矩阵的列中，所以我们把 $x^{(1)}$ 放到矩阵的第一列中，$x^{(2)}$ 放到第二列，$x^{(m)}$ 放到第 $m$ 列，$m$ 是训练集的样本数量，然后这个矩阵的高度记为 $n_x$，注意有时候可能因为其他某些原因，矩阵 $X$ 会由训练样本按照行堆叠起来而不是列，如下图所示：$x^{(1)}$ 到 $x^{(m)}$ 的转置，但在实现神经网络的时候，使用左边的形式，会让实现过程更加简单。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020040416120555.png)

$X$ 是一个规模为 $n_x\times m$ 的矩阵，当你用 $Python$ 实现的时候，你会看到 $X.shape$，用以显示矩阵的规模，即 $X.shape$ 等于 $(n_x,m)$

同理，可以把标签 $y$ 放在列中将会简化后续计算，可以定义大些的 $Y$ 等于 $y^{(1)},y^{(2)},...,y^{(m)}$，所以这里是一个规模为 $1\times m$ 的矩阵，$Y.shape = (1,m)$

一个好的符号约定能够将不同训练样本的数据很好地组织起来

### Logistic Regression

对于二分类问题，给定输入 $X$，则有输出预测 $\hat{y}=P(y=1|x)$。上文提到过，$X$ 是一个 $n_x$ 维的向量，用 $w$ 表示逻辑回归的参数，$b$ 表示偏差，则有 $\hat{y}=w^Tx+b$

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404162203802.png)

此时得到一个关于输入 $x$ 的线性函数，实际上这是在做线性回归时用到的，但是对于二分类问题来讲并不是一个好的算法，所以可以将上式作为自变量放到 sigmoid 函数中，可以将线性函数转化为非线性函数。

下图为 sigmoid 函数的图像，$\sigma(z)=\frac{1}{1+e^{-z}}$：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404162822815.png)

逻辑回归就是调整参数 $w$ 和 $b$，让 $\hat{y}$ 变得更加准确。在神经网络的学习中，通常将参数 $w$ 和 $b$ 分开，在这里参数 $b$ 是一种偏置。还有一种处理此问题的其他符号表示，如下图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404163746291.png)

### Logistic Regression cost function

为了训练逻辑回归模型的参数 w 和参数 b ，我们需要一个代价函数，通过训练代价函数来得到参数 w 和参数 b。先看一下逻辑回归的输出函数：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404164350355.png)

损失函数（误差函数）$L(\hat{y},y)$

用来衡量算法的运行情况，即预测值和真实值的接近程度，通常为预测值和真实值差的平方或平方的一半，但是在逻辑回归中一般不这么做，因为在学习逻辑回归参数时，会发现优化目标不是凸优化，只能得到多个局部最优值，用梯度下降法可能找不到全局最优值，所以通常会定义另一个损失函数：

$L(\hat{y},y)=−y\log(\hat{y})−(1−y)\log(1−\hat{y})$

当 $y=1$ 时，$L=-log(\hat{y})$，如果想要损失函数 $L$ 尽可能小，那么 $\hat{y}$ 就要尽可能大，因为 sigmoid 函数的缘故，$\hat{y}$ 会无限接近于 1

当 $y=0$ 时，$L=-\log(1-\hat{y})$，如果想要损失函数 $L$ 尽可能小，那么 $\hat{y}$ 就要尽可能小，因为 sigmoid 函数的缘故，$\hat{y}$ 会无限接近于 0

其实有很多函数和这个函数效果类似，就是如果 y 等于 1，就尽可能让 $\hat{y}$ 变大；如果 y 等于 0，就尽可能让 $\hat{y}$ 变小。**损失函数是在单个训练样本中定义的，它衡量的是算法在单个训练样本中的表现。**

为了衡量算法在全部训练样本上的表现，需要定义一个算法的代价函数，对 m 个样本的损失求和然后除以 m：

$J(w,b)=\frac{1}{m}\sum\limits_{i=1}^m{L(\hat{y}^{(i)},y^{(i)})=\frac{1}{m}\sum\limits_{i=1}^m{(−y^{(i)}\log\hat{y}^{(i)}−(1−y^{(i)})\log(1−\hat{y}^{(i)}))}}$

损失函数只适用于单个训练样本，而代价函数是参数的总代价，所以在训练逻辑回归模型时候，我们需要找到合适的 w 和 b ，来让代价函数 J 的总代价降到最低。 
